version: '3'
services:
  master:
    image: dwsmith1983/hadoop_spark_docker_swarm.datascience
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8001:8080
      - 8888:8888
    volumes:
      - ./data:/tmp/data
      - ./py-src:/cluster_data
      - nfsshare:/shared_cluster_data
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager]

  worker:
    image: dwsmith1983/hadoop_spark_docker_swarm.datascience
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
    hostname: worker
    depends_on:
      - master
    links:
      - master
    ports:
      - 8081:8081
    volumes:
      - ./data:/tmp/data
      - nfsshare:/shared_cluster_data
    deploy:
      replicas: 4
      placement:
        constraints: [node.role == worker]

  namenode:
    image: dwsmith1983/hadoop_spark_docker_swarm.namenode
    hostname: namenode
    ports:
      - 9870:9870
      - 9820:9820
    volumes:
      - ./namenode:/hadoop/dfs/name
      - ./hadoop-data:/hadoop-data
    environment:
      - CLUSTER_NAME=production
    env_file:
      - ./hadoop.env
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints: [node.role == manager]

  datanode:
    image: dwsmith1983/hadoop_spark_docker_swarm.datanode
    volumes:
      - ./datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "<ip>:9870"
    deploy:
      replicas: 4
      placement:
        constraints: [node.role == worker]

volumes:
  nfsshare:
    driver: local
    driver_opts:
      type: "nfs"
      o: "addr=<ip>,nfsvers=4"
      device: ":/"

networks:
    default:
        external:
            name: hadoop-spark-swarm-network
